# @package _global_
# line above ensures that the experiment overrides root settings:
# we need this so our configs affect the global/root config. it has to be the first line in the file

defaults:
  - override /model: multi_model_nlp.yaml
  - override /model/large_model: nlp_GLUETransformer.yaml
  - override /datamodule: nlp_GLUEDataModule.yaml
  - override /callbacks: val_loss.yaml
  - override /selection_method: uniform_selection.yaml

trainer:
  max_epochs: 100 
  gpus: 0

datamodule:
  data_dir: 'C:\Users\William\Documents\Programming\PhD\Datasets\'
  batch_size: 320
  stage: 'fit'
  task_name: 'cola'

optimizer:
  weight_decay: 0.01
  lr: 1e-6

logger:
  wandb:
    project: "RobustRHO-NLP"
    tags: ['NLP', 'uniform']

